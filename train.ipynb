{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bastien Faivre\\.conda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from utils import *\n",
    "from model import UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 400\n",
    "IMAGE_WIDTH = 400\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAIN_IMAGE_DIR = \"train_data/train_images/\"\n",
    "TRAIN_GROUNDTRUTH_DIR = \"train_data/train_masks/\"\n",
    "VAL_IMAGE_DIR = \"train_data/val_images/\"\n",
    "VAL_GROUNDTRUTH_DIR = \"train_data/val_masks/\"\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "# define loss function, optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_loader, val_loader = get_loaders(\n",
    "    TRAIN_IMAGE_DIR,\n",
    "    TRAIN_GROUNDTRUTH_DIR,\n",
    "    VAL_IMAGE_DIR,\n",
    "    VAL_GROUNDTRUTH_DIR,\n",
    "    BATCH_SIZE,\n",
    "    train_transform,\n",
    "    val_transforms,\n",
    "    NUM_WORKERS,\n",
    "    PIN_MEMORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute F1 score\n",
    "def f1_score(preds, target, threshold=0.5, eps=1e-7):\n",
    "    preds = (preds > threshold).float()\n",
    "    target = target.float()\n",
    "    intersection = (preds * target).sum((1, 2))\n",
    "    union = (preds + target).sum((1, 2))\n",
    "    return ((2. * intersection + eps) / (union + eps)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_loader, epoch, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_f1 = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_f1 += f1_score(predictions, target)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tF1: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), f1_score(predictions, target)))\n",
    "    train_loss /= len(train_loader)\n",
    "    train_f1 /= len(train_loader)\n",
    "    print('Train set: Average loss: {:.4f}\\tAverage F1: {:.4f}'.format(train_loss, train_f1))\n",
    "    return train_loss, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_f1 = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.float().unsqueeze(1).to(device)\n",
    "        predictions = model(data)\n",
    "        val_loss += criterion(predictions, target).item()\n",
    "        val_f1 += f1_score(predictions, target)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_f1 /= len(val_loader)\n",
    "    print('Validation set: Average loss: {:.4f}\\tAverage F1: {:.4f}'.format(val_loss, val_f1))\n",
    "    return val_loss, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/80 (0%)]\tLoss: 0.535924\tF1: 0.683125\n",
      "Train Epoch: 0 [40/80 (50%)]\tLoss: 0.464567\tF1: 0.758750\n",
      "Train set: Average loss: 0.4649\tAverage F1: 0.6521\n",
      "Validation set: Average loss: 0.5297\tAverage F1: 1.0000\n",
      "=> Saving checkpoint\n",
      "Train Epoch: 1 [0/80 (0%)]\tLoss: 0.408914\tF1: 0.803125\n",
      "Train Epoch: 1 [40/80 (50%)]\tLoss: 0.350653\tF1: 0.890625\n",
      "Train set: Average loss: 0.3577\tAverage F1: 0.8738\n",
      "Validation set: Average loss: 0.3206\tAverage F1: 1.0000\n",
      "=> Saving checkpoint\n",
      "Train Epoch: 2 [0/80 (0%)]\tLoss: 0.310879\tF1: 0.940625\n",
      "Train Epoch: 2 [40/80 (50%)]\tLoss: 0.297009\tF1: 0.866875\n",
      "Train set: Average loss: 0.2947\tAverage F1: 0.9291\n",
      "Validation set: Average loss: 0.2895\tAverage F1: 0.9097\n",
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "train_loss_history = []\n",
    "train_f1_history = []\n",
    "val_loss_history = []\n",
    "val_f1_history = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    train_loss, train_f1 = train_epoch(model, optimizer, criterion, train_loader, epoch, DEVICE)\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_f1_history.append(train_f1)\n",
    "\n",
    "    val_loss, val_f1 = validate(model, criterion, val_loader, DEVICE)\n",
    "\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_f1_history.append(val_f1)\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\":optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7e05192452f125cb13be8762cc761224f4d65b3e92bafdd379139e00305cbc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
